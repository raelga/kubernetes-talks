# Kubernetes from Scratch

- [Kubernetes from Scratch](#kubernetes-from-scratch)
  - [Start up an instance](#start-up-an-instance)
  - [Before starting](#before-starting)
    - [Tunneling to the remote host ports](#tunneling-to-the-remote-host-ports)
    - [Short url usage](#short-url-usage)
  - [First component: `etcd`](#first-component-etcd)
    - [`etcd` setup](#etcd-setup)
    - [Launch `etcd`](#launch-etcd)
    - [Test `etcd`](#test-etcd)
    - [Check `etcd` content](#check-etcd-content)
  - [Download the Kubernetes Control Plane binaries](#download-the-kubernetes-control-plane-binaries)
    - [Client binaries](#client-binaries)
    - [Master binaries](#master-binaries)
    - [Node binaries](#node-binaries)
  - [Second component: Kubernetes API Server](#second-component-kubernetes-api-server)
    - [Start the `kube-apiserver`](#start-the-kube-apiserver)
    - [Check the `etcd` content](#check-the-etcd-content)
  - [Create a ConfigMap](#create-a-configmap)
    - [Check existing `configmaps`](#check-existing-configmaps)
    - [Create a new `ConfigMap`](#create-a-new-configmap)
    - [Check again the `ConfigMap` resources in the _default_ `Namespace`](#check-again-the-configmap-resources-in-the-default-namespace)
  - [Setup `kubectl`](#setup-kubectl)
    - [Define a the `localhost:8080` cluster](#define-a-the--localhost8080-cluster)
    - [Define a `localhost` context](#define-a-localhost-context)
    - [Set the current context to `localhost`](#set-the-current-context-to-localhost)
    - [Check the cluster `ConfigMaps` with `kubectl`](#check-the-cluster-configmaps-with-kubectl)
    - [Inspect the `hello-cm` `ConfigMap` with `kubectl` as `json`](#inspect-the-hello-cm-configmap-with-kubectl-as-json)
  - [Create a `Deployment` object](#create-a-deployment-object)
    - [Create the `hello-dep.json` deployment with `curl` in `api/v1/namespaces/default/deployments`](#create-the-hello-depjson-deployment-with-curl-in-apiv1namespacesdefaultdeployments)
    - [Create the `hello-dep.json` deployment with `curl` in `apis/apps/v1/namespaces/default/deployments`](#create-the-hello-depjson-deployment-with-curl-in-apisappsv1namespacesdefaultdeployments)
    - [Check the deployment in `etcd`](#check-the-deployment-in-etcd)
    - [Check the deployment with `kubectl`](#check-the-deployment-with-kubectl)
    - [Check if there is any differences between the deployed with `curl` and the `kubectl` `yaml` version](#check-if-there-is-any-differences-between-the-deployed-with-curl-and-the-kubectl-yaml-version)
    - [Check the `ReplicaSets` generated by the `Deployment`](#check-the-replicasets-generated-by-the-deployment)
    - [Check `all` the cluster resources](#check-all-the-cluster-resources)
  - [Third component: kube-controller-manager](#third-component-kube-controller-manager)
    - [Watch the cluster changes](#watch-the-cluster-changes)
    - [Start the `kube-controller-manager`](#start-the-kube-controller-manager)
    - [Review the status of the `hello-dep` `ReplicaSets` after starting the `kube-controller-manager`](#review-the-status-of-the-hello-dep-replicasets-after-starting-the-kube-controller-manager)
    - [Review the status of the `hello-dep` `Pods`after staring the `kube-controller-manager`](#review-the-status-of-the-hello-dep-podsafter-staring-the-kube-controller-manager)
  - [Forth component: `kube-scheduler`](#forth-component-kube-scheduler)
    - [Watch the `Pods`](#watch-the-pods)
    - [Start the `kube-scheduler`](#start-the-kube-scheduler)
    - [Check `Pods` status](#check-pods-status)
    - [Check the nodes](#check-the-nodes)
  - [Fifth component: `kubelet`](#fifth-component-kubelet)
    - [Create a .kube/config file for kubelet](#create-a-kubeconfig-file-for-kubelet)
    - [Check the resulting .kube/config file](#check-the-resulting-kubeconfig-file)
    - [Check `docker ps` to view the actual containers running](#check-docker-ps-to-view-the-actual-containers-running)
  - [Expose the `Deploment` with a `Service`](#expose-the-deploment-with-a-service)
  - [Try to connect to the service IP](#try-to-connect-to-the-service-ip)
  - [Sixth component: `kube-proxy`](#sixth-component-kube-proxy)
  - [Delete everything](#delete-everything)

## Start up an instance

> ## **Open a new terminal named `instance`**

You can run a local VM or use a cloud server. For this example, we'll be deploying an EC2 instance in AWS using terraform.

Setup your terraform AWS credentials and run `tf init`

- Command in the `instance` terminal

```bash
tf init
```

- Expected output:

```bash

Initializing the backend...
Initializing modules...
- ec2 in ../00-Instance-Academy/terraform/modules/aws/ec2-academy/instance

Initializing provider plugins...
- Finding latest version of hashicorp/random...
- Finding latest version of hashicorp/aws...
- Installing hashicorp/random v3.6.0...
- Installed hashicorp/random v3.6.0 (signed by HashiCorp)
- Installing hashicorp/aws v5.36.0...
- Installed hashicorp/aws v5.36.0 (signed by HashiCorp)

Terraform has created a lock file .terraform.lock.hcl to record the provider
selections it made above. Include this file in your version control repository
so that Terraform can guarantee to make the same selections by default when
you run "terraform init" in the future.

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
```

Then run `tf apply`:

- Command:

```bash
tf apply -auto-approve
```

- Expected output:

```bash
data.aws_vpc.default: Reading...
module.ec2.data.aws_key_pair.managed[0]: Reading...
data.aws_region.current: Reading...
module.ec2.data.aws_iam_role.this: Reading...
module.ec2.data.aws_ami.latest: Reading...
....

module.ec2.aws_eip.this: Creating...
module.ec2.aws_eip.this: Creation complete after 3s [id=eipalloc-062dcf3dd6a414a1b]

Apply complete! Resources: 5 added, 0 changed, 0 destroyed.

Outputs:

public_ip = "34.202.212.85"
ssh_cmd = "ssh -A ec2-user@34.202.212.85"
```

SSH into the instance.

- Command in the `instance` terminal

```bash
ssh $(tf output -raw ssh_host)
```

- Expected output:

```bash
...
   ,     #_
   ~\_  ####_        Amazon Linux 2
  ~~  \_#####\
  ~~     \###|       AL2 End of Life is 2025-06-30.
  ~~       \#/ ___
   ~~       V~' '->
    ~~~         /    A newer version of Amazon Linux is available!
      ~~._.   _/
         _/ _/       Amazon Linux 2023, GA and supported until 2028-03-15.
       _/m/'           https://aws.amazon.com/linux/amazon-linux-2023/
....
```

---

```
####################################################
#############         storage           ############
####################################################
```

---

## Before starting

### Tunneling to the remote host ports

If your are using a remote server and want to access to the services from your local computer, is recommended connect to the instance building a tunnel to the service ports. For demo purposes and using the **simpliest** setup possible, we're not going to use authentication neither enable secure communication between services.

For the `kube-apiserver`, use `ssh -L 8080:localhost:8080 34.254.155.10`.
For the `etcd` server, use `ssh -L 2379:localhost:2379 34.254.155.10`.

### Short url usage

To be easy to remember, we will use a shortlinks under the `go.rael.dev` domain.

For example, `go.rael.dev/etcd-v35` points to the GitHub etcd-3.3013 tarball at `https://github.com/etcd-io/etcd/releases/download/v3.5.0/etcd-v3.5.0-linux-amd64.tar.gz`.

Feel free to _resolve_ the links by using `curl -I`

- Command in the `instance` terminal

```bash
curl -I go.rael.dev/etcd-v35
```

- Expected output

```
HTTP/1.1 302 Found
Server: nginx
Date: Mon, 18 Oct 2021 14:03:36 GMT
Content-Type: text/html; charset=utf-8
Content-Length: 174
Cache-Control: private, max-age=90
Location: https://github.com/etcd-io/etcd/releases/download/v3.5.0/etcd-v3.5.0-linux-amd64.tar.gz
Strict-Transport-Security: max-age=1209600
Via: 1.1 google
```

Or

- Command in the `instance` terminal

```bash
curl -o /dev/null -I -s go.rael.dev/etcd-v35 -w '%{redirect_url}'
```

- Expected output

```bash
https://github.com/etcd-io/etcd/releases/download/v3.5.0/etcd-v3.5.0-linux-amd64.tar.gz
```

## First component: `etcd`

> ## **Open a new terminal named `etcd`**

### `etcd` setup

SSH into the instance, establishing a tunnel to the etcd port `2379`.
This will be our `etcd` terminal.

- Command in the `etcd` terminal

```bash
ssh -L 2379:localhost:2379 $(tf output -raw ssh_host)
```

Download the a stable version of etcd v3, for this demo, v3.5.0.

- Command in the `etcd` terminal

```bash
curl -sqL go.rael.dev/etcd-v35 | tar -zxvf -
```

- Expected output

```
etcd-v3.5.0-linux-amd64/
etcd-v3.5.0-linux-amd64/Documentation/
etcd-v3.5.0-linux-amd64/Documentation/dev-guide/
etcd-v3.5.0-linux-amd64/Documentation/dev-guide/apispec/
etcd-v3.5.0-linux-amd64/Documentation/dev-guide/apispec/swagger/
...
etcd-v3.5.0-linux-amd64/etcdutl
etcd-v3.5.0-linux-amd64/etcdctl
etcd-v3.5.0-linux-amd64/etcd
```

### Launch `etcd`

- Command in the `etcd` terminal

```bash
~/etcd-v3.5.0-linux-amd64/etcd -log-level debug
```

- Expected output

```json
{"level":"info","ts":"2021-10-18T14:15:19.544Z","caller":"etcdmain/etcd.go:72","msg":"Running: ","args":["/home/rael/etcd-v3.5.0-linux-amd64/etcd","-log-level","debug"]}
{"level":"warn","ts":"2021-10-18T14:15:19.544Z","caller":"etcdmain/etcd.go:104","msg":"'data-dir' was empty; using default","data-dir":"default.etcd"}
{"level":"info","ts":"2021-10-18T14:15:19.544Z","caller":"embed/etcd.go:131","msg":"configuring peer listeners","listen-peer-urls":["http://localhost:2380"]}
{"level":"info","ts":"2021-10-18T14:15:19.544Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["http://localhost:2379"]}
{"level":"info","ts":"2021-10-18T14:15:19.544Z","caller":"embed/etcd.go:307","msg":"starting an etcd server","etcd-version":"3.5.0","git-sha":"946a5a6f2","go-version":"go1.16.3","go-os":"linux","go-arch":"amd64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"default","data-dir":"default.etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"default.etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":100000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["http://localhost:2380"],"listen-peer-urls":["http://localhost:2380"],"advertise-client-urls":["http://localhost:2379"],"listen-client-urls":["http://localhost:2379"],"listen-metrics-urls":[],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"default=http://localhost:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":false,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
```

### Test `etcd`

- Command in the `instance` terminal

```bash
curl http://localhost:2379/health
```

- Expected output

```json
{ "health": "true", "reason": "" }
```

- Expected log in the `etcd` server

```json
{"level":"debug","ts":"2021-10-18T14:20:52.428Z","caller":"etcdhttp/metrics.go:202","msg":"serving /health true"}
{"level":"debug","ts":"2021-10-18T14:20:52.428Z","caller":"etcdhttp/metrics.go:83","msg":"/health OK","status-code":200}
```

### Optional: etcd web interface

https://github.com/evildecay/etcdkeeper/tree/master

```
etcdkeeper
```

```
2024-02-15 16:23:03.731343 I | listening on 0.0.0.0:52379
2024-02-15 16:23:15.988588 I | POST v3 connect success.
2024-02-15 16:23:16.624809 I | GET v3 /
```

Visit http://localhost:52379/etcdkeeper/

Other options:

- https://etcd.io/docs/v3.4/integrations/

### Check `etcd` content

- Command in the `instance` terminal

```bash
curl -sq -L http://localhost:2379/v3/kv/put -X POST \
  -d "{\"key\": \"$(echo -n /test | base64)\", \"value\": \"$(echo -n Hello world from cURL | base64)\"}" | jq .
```

- Expected output

```json
{
  "header": {
    "cluster_id": "14841639068965178418",
    "member_id": "10276657743932975437",
    "revision": "2",
    "raft_term": "2"
  }
}
```

- Expected log in the `etcd` server

```json
{"level":"debug","ts":"2021-10-18T16:07:19.628Z","caller":"etcdserver/server.go:2107","msg":"Applying entries","num-entries":1}
{"level":"debug","ts":"2021-10-18T16:07:19.628Z","caller":"etcdserver/server.go:2110","msg":"Applying entry","index":5,"term":2,"type":"EntryNormal"}
{"level":"debug","ts":"2021-10-18T16:07:19.628Z","caller":"etcdserver/server.go:2160","msg":"apply entry normal","consistent-index":4,"entry-index":5,"should-applyV3":true}
{"level":"debug","ts":"2021-10-18T16:07:19.628Z","caller":"etcdserver/server.go:2187","msg":"applyEntryNormal","raftReq":"header:<ID:7587857922959450373 > put:<key:\"/test\" value:\"Hello world from cURL\" > "}
{"level":"debug","ts":"2021-10-18T16:07:19.630Z","caller":"v3rpc/interceptor.go:182","msg":"request stats","start time":"2021-10-18T16:07:19.628Z","time spent":"1.577348ms","remote":"127.0.0.1:33276","response type":"/etcdserverpb.KV/Put","request count":1,"request size":30,"response count":0,"response size":28,"request content":"key:\"/test\" value_size:21 "}
```

To make the interaction more user friendly, we can use the `etcdctl` command line CLI.
Use it locally thanks to the SSH tunnel, or with `~/etcd-v3.5.0-linux-amd64/etcdctl` at the `instance` terminal.

To make the commands friendly to both scenarios, install `etcdctl` in the EC2 instance `/usr/local/bin` path using:

```
sudo install ~/etcd-v3.5.0-linux-amd64/etcdctl /usr/local/bin/
```

- Command in the `instance` terminal

```bash
etcdctl get / --prefix --keys-only
```

- Expected output

The expected output should be `/key` created in the previous step.

```bash
/test
```

- Expected log in the `etcd` server

```json
{
  "level": "debug",
  "ts": "2021-10-18T16:10:42.381Z",
  "caller": "v3rpc/interceptor.go:182",
  "msg": "request stats",
  "start time": "2021-10-18T16:10:42.381Z",
  "time spent": "136.291µs",
  "remote": "127.0.0.1:33284",
  "response type": "/etcdserverpb.KV/Range",
  "request count": 0,
  "request size": 8,
  "response count": 1,
  "response size": 45,
  "request content": "key:\"/\" range_end:\"0\" keys_only:true "
}
```

Retrieve `/test` content using `etcdctl`

- Command in the `instance` terminal

```
etcdctl get /test
```

- Expected output

```
/test
Hello world from cURL
```

- Server log

```json
{
  "level": "debug",
  "ts": "2021-10-18T16:12:43.545Z",
  "caller": "v3rpc/interceptor.go:182",
  "msg": "request stats",
  "start time": "2021-10-18T16:12:43.545Z",
  "time spent": "144.691µs",
  "remote": "127.0.0.1:33286",
  "response type": "/etcdserverpb.KV/Range",
  "request count": 0,
  "request size": 7,
  "response count": 1,
  "response size": 68,
  "request content": "key:\"/test\" "
}
```

Update `/test` content using `etcdctl`

- Command in the `instance` terminal

```
etcdctl put /test "Hello world from etcdctl"
```

- Expected output

```
OK
```

- Server log

```json
{"level":"debug","ts":"2021-10-18T16:15:23.208Z","caller":"etcdserver/server.go:2187","msg":"applyEntryNormal","raftReq":"header:<ID:7587857922959450380 > put:<key:\"/test\" value:\"Hello world from etcdctl\" > "}
{"level":"debug","ts":"2021-10-18T16:15:23.208Z","caller":"v3rpc/interceptor.go:182","msg":"request stats","start time":"2021-10-18T16:15:23.208Z","time spent":"475.565µs","remote":"127.0.0.1:33292","response type":"/etcdserverpb.KV/Put","request count":1,"request size":33,"response count":0,"response size":28,"request content":"key:\"/test\" value_size:24 "}
```

Check the value from etcdctl

```bash
etcdctl get /test
```

```
/test
Hello world from etcdctl
```

When using etcdtl, data is encoded in base64 automatically:

```
curl -sq -L http://localhost:2379/v3/kv/range \
  -X POST -d '{"key": "AA==", "range_end": "AA=="}' | jq .
```

(`AA==` is `\0` in base64, full range of keys)

We can still get the values from curl just encoding the key and decoding the value:

```bash
curl -sq -L http://localhost:2379/v3/kv/range \
 -X POST -d "{\"key\": \"$(echo -n /test | base64)\"}" | jq .
```

```json
{"header":{"cluster_id":"14841639068965178418","member_id":"10276657743932975437","revision":"5","raft_term":"2"},"kvs":[{"key":"L3Rlc3Q=","create_revision":"2","mod_revision":"5","version":"4","value":"SGVsbG8gd29ybGQgZnJvbSBldGNkY3Rs"}],"count":"1"}%
```

With the `base64` decoding

```bash
echo -n $(curl -sqL http://localhost:2379/v3/kv/range -X POST -d "{\"key\": \"$(echo -n /test | base64)\"}" | jq -r '.kvs[0].value') | base64 -d && echo
```

```
Hello world from etcdctl
```

---

```
####################################################
#############           API             ############
####################################################
```

---

## Download the Kubernetes Control Plane binaries

Then download the kubernetes binaries.

- Command in the `instance` terminal

```bash
curl -sqL go.rael.dev/k8s1-16-0rc2 | tar -zvxf -
```

- Expected output

```bash
kubernetes/
kubernetes/server/
kubernetes/server/bin/
kubernetes/server/bin/kube-scheduler.tar
kubernetes/server/bin/mounter
kubernetes/server/bin/kube-scheduler.docker_tag
kubernetes/server/bin/kubeadm
kubernetes/server/bin/kube-controller-manager.docker_tag
kubernetes/server/bin/hyperkube
kubernetes/server/bin/kube-apiserver.docker_tag
kubernetes/server/bin/kube-apiserver
kubernetes/server/bin/kubectl
kubernetes/server/bin/kube-proxy.docker_tag
kubernetes/server/bin/kube-apiserver.tar
kubernetes/server/bin/kube-proxy.tar
kubernetes/server/bin/kubelet
kubernetes/server/bin/apiextensions-apiserver
kubernetes/server/bin/kube-controller-manager.tar
kubernetes/server/bin/kube-proxy
kubernetes/server/bin/kube-scheduler
kubernetes/server/bin/kube-controller-manager
kubernetes/kubernetes-src.tar.gz
kubernetes/LICENSES
kubernetes/addons/
```

As you can see, there are several binaries in this release tarball. For this lab, we will use the binaries necessary for the Kubernetes Control Plane:

### Client binaries

- ~/kubernetes/server/bin/kubectl

### Master binaries

- ~/kubernetes/server/bin/kube-apiserver
- ~/kubernetes/server/bin/kube-scheduler
- ~/kubernetes/server/bin/kube-controller-manager

### Node binaries

- ~/kubernetes/server/bin/kubelet
- ~/kubernetes/server/bin/kube-proxy

## Second component: Kubernetes API Server

> ## **Open a new terminal named `api`**

SSH into the instance, establishing a tunnel to the api port `8080`.
This will be our `api` terminal.

- Command in the `api` terminal

```bash
ssh -L 8080:localhost:8080 $(tf output -raw ssh_host)
```

### Start the `kube-apiserver`

In the previous step, we downloaded all the binaries from the Kubernetes release.

In this step, we will start the Kubernetes API server that can be found in `~/kubernetes/server/bin/kube-apiserver`. If possible, keep the `etcd` logs open to see the activity generated by the `kube-apiserver` start up.

- Command

There are a couple of flags added to the `kube-apiserver`: `--etcd-servers` pointing to the local `etcd` that we just launched and `--v 3` to increase the verbosity level of the log.

```bash
sudo ~/kubernetes/server/bin/kube-apiserver --etcd-servers=http://localhost:2379 --v 3
```

- Expected output:

```
I0914 13:23:31.519409   13367 flags.go:33] FLAG: --add-dir-header="false"
I0914 13:23:31.519475   13367 flags.go:33] FLAG: --address="127.0.0.1"
I0914 13:23:31.519483   13367 flags.go:33] FLAG: --admission-control="[]"
I0914 13:23:31.519503   13367 flags.go:33] FLAG: --admission-control-config-file=""
I0914 13:23:31.519511   13367 flags.go:33] FLAG: --advertise-address="<nil>"
I0914 13:23:31.519516   13367 flags.go:33] FLAG: --allow-privileged="false"
I0914 13:23:31.519525   13367 flags.go:33] FLAG: --alsologtostderr="false"
I0914 13:23:31.519529   13367 flags.go:33] FLAG: --anonymous-auth="true"
...
I0914 13:23:31.521949   13367 server.go:666] Initializing cache sizes based on 0MB limit
I0914 13:23:31.522205   13367 server.go:149] Version: v1.16.0-rc.2
I0914 13:23:31.881250   13367 plugins.go:158] Loaded 10 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,MutatingAdmissionWebhook,RuntimeClass.
I0914 13:23:31.881283   13367 plugins.go:161] Loaded 7 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,Priority,PersistentVolumeClaimResize,ValidatingAdmissionWebhook,RuntimeClass,ResourceQuota.
...
I0914 13:24:51.649749   13391 httplog.go:90] GET /healthz: (711.457µs) 0 [kube-apiserver/v1.16.0 (linux/amd64) kubernetes/4cb51f0 [::1]:50188]
I0914 13:24:51.749652   13391 healthz.go:191] [+]ping ok
[+]log ok
[+]etcd ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[-]poststarthook/scheduling/bootstrap-system-priority-classes failed: reason withheld
[-]poststarthook/ca-registration failed: reason withheld
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
healthz check failed
I0914 13:24:51.749759   13391 httplog.go:90] GET /healthz: (683.587µs) 0 [kube-apiserver/v1.16.0 (linux/amd64) kubernetes/4cb51f0 [::1]:50188]
I0914 13:24:51.831507   13391 controller.go:107] OpenAPI AggregationController: Processing item
I0914 13:24:51.831535   13391 controller.go:130] OpenAPI AggregationController: action for item : Nothing (removed from the queue).
I0914 13:24:51.831600   13391 controller.go:130] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
...
I0914 13:25:41.856486   13391 httplog.go:90] GET /api/v1/namespaces/default/endpoints/kubernetes: (816.858µs) 200 [kube-apiserver/v1.16.0 (linux/amd64) kubernetes/4cb51f0 [::1]:50188]
```

And we can see a lot of new keys in etcd:

```
curl -sq -L http://localhost:2379/v3/kv/range \
  -X POST -d '{"key": "AA==", "range_end": "AA=="}' | jq .
```

### Check the `etcd` content

During the start of the `kube-apiserver`, you probably noticed that the `etcd` logs started to show a lot of activity.

- Command in the `instance` terminal

```bash
etcdctl get / --prefix --keys-only
```

- Expected output:

As you can see, now the `etcd` database has been populated with the Kubernetes API resources.

```bash
/registry/apiregistration.k8s.io/apiservices/v1.

/registry/apiregistration.k8s.io/apiservices/v1.admissionregistration.k8s.io

/registry/apiregistration.k8s.io/apiservices/v1.apiextensions.k8s.io

...
/registry/ranges/servicenodeports

/registry/services/endpoints/default/kubernetes

/registry/services/specs/default/kubernetes
```

- Expected `etcd` logs output:

And in the `etcd` server logs, we can see that the key count is now 42: `response count = 42`.

```json
{
  "level": "debug",
  "ts": "2021-10-18T18:01:50.093Z",
  "caller": "v3rpc/interceptor.go:182",
  "msg": "request stats",
  "start time": "2021-10-18T18:01:50.093Z",
  "time spent": "203.912µs",
  "remote": "127.0.0.1:33502",
  "response type": "/etcdserverpb.KV/Range",
  "request count": 0,
  "request size": 8,
  "response count": 42,
  "response size": 2889,
  "request content": "key:\"/\" range_end:\"0\" keys_only:true "
}
```

---

```
####################################################
#############   API Server URL schema   ############
####################################################
```

---

## Create a ConfigMap

> ## **Open a new terminal named `local`**

### Check existing `configmaps`

- Command in the `local` terminal

```bash
curl -sq -X GET http://localhost:8080/api/v1/namespaces/default/configmaps
```

- Expected output

The expected result is an empty list of `ConfigMapList`.

```json
{
  "kind": "ConfigMapList",
  "apiVersion": "v1",
  "metadata": {
    "selfLink": "/api/v1/namespaces/default/configmaps",
    "resourceVersion": "158"
  },
  "items": []
}
```

### Create a new `ConfigMap`

- Command in the `local` terminal

For demo purposes, we will write the `json` inline, but you can check the unfurled version in [hello-cm.json](hello-manifests/hello-cm.json):

```bash
curl -sq -v -X POST \
  -H "Content-Type: application/json" \
  -d '{ "apiVersion": "v1", "kind": "ConfigMap", "metadata": { "name": "hello-cm" }, "data": { "GREETINGS": "Hello folks" } }' \
   http://localhost:8080/api/v1/namespaces/default/configmaps
```

- Expected output:

```
*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
> POST /api/v1/namespaces/default/configmaps HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.54.0
> Accept: */*
> Content-Type: application/json
> Content-Length: 135
>
* upload completely sent off: 135 out of 135 bytes
< HTTP/1.1 201 Created
< Cache-Control: no-cache, private
< Content-Type: application/json
< Date: Sat, 14 Sep 2019 22:59:42 GMT
< Content-Length: 379
<
{
  "kind": "ConfigMap",
  "apiVersion": "v1",
  "metadata": {
    "name": "hello-cm",
    "namespace": "default",
    "selfLink": "/api/v1/namespaces/default/configmaps/hello-cm",
    "uid": "e973e1b1-7012-480e-97d7-8b3f502a7b66",
    "resourceVersion": "299",
    "creationTimestamp": "2019-09-14T22:59:42Z"
  },
  "data": {
    "GREETING": "Hello folks"
  }
* Connection #0 to host localhost left intact
}
```

### Check again the `ConfigMap` resources in the _default_ `Namespace`

- Command in the `local` terminal

```bash
curl -sq -X GET http://localhost:8080/api/v1/namespaces/default/configmaps
```

- Expected output:

  ```json
  {
    "kind": "ConfigMapList",
    "apiVersion": "v1",
    "metadata": {
      "selfLink": "/api/v1/namespaces/default/configmaps",
      "resourceVersion": "326"
    },
    "items": [
      {
        "metadata": {
          "name": "hello-cm",
          "namespace": "default",
          "selfLink": "/api/v1/namespaces/default/configmaps/hello-cm",
          "uid": "e973e1b1-7012-480e-97d7-8b3f502a7b66",
          "resourceVersion": "299",
          "creationTimestamp": "2019-09-14T22:59:42Z"
        },
        "data": {
          "GREETING": "Hello folks"
        }
      }
    ]
  }
  ```

- Output in `kube-apiserver` logs

```
I0914 23:12:23.322801   27544 httplog.go:90] POST /api/v1/namespaces/default/configmaps: (2.596778ms) 201 [curl/7.54.0 127.0.0.1:60496]
```

- Output in `etcd` logs

```
2019-09-14 22:59:42.365456 D | etcdserver/api/v3rpc: start time = 2019-09-14 22:59:42.365136267 +0000 UTC m=+533.472256982, time spent = 280.684µs, remote = 127.0.0.1:40330, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 193, response count = 0, response size = 40, request content = compare:<target:MOD key:"/registry/configmaps/default/hello-cm" mod_revision:0 > success:<request_put:<key:"/registry/configmaps/default/hello-cm" value_size:148 >> failure:<>
```

- Command in the `local` or `instance` terminal

```bash
etcdctl get /registry/configmaps/default/hello-cm -w fields
```

```
"ClusterID" : 14841639068965178418
"MemberID" : 10276657743932975437
"Revision" : 380
"RaftTerm" : 2
"Key" : "/registry/configmaps/default/hello-cm"
"CreateRevision" : 299
"ModRevision" : 299
"Version" : 1
"Value" : "k8s\x00\n\x0f\n\x02v1\x12\tConfigMap\x12y\nM\n\bhello-cm\x12\x00\x1a\adefault\"\x00*$e973e1b1-7012-480e-97d7-8b3f502a7b662\x008\x00B\b\b\xde\xe1\xf5\xeb\x05\x10\x00z\x00\x12(\n\bGREETING\x12\x1cHello folks\x1a\x00\"\x00"
"Lease" : 0
"More" : false
"Count" : 1
```

## Setup `kubectl` on your local computer

The API Server was spawn on a shell with a SSH tunnel listening at localhost:8080.

### Define a the `localhost:8080` cluster

- Command in the `local`

```bash
kubectl config set-cluster localhost --server localhost:8080
```

- Expected output

```bash
Cluster "localhost" set.
```

### Define a `localhost` context

- Command in the `local` terminal

```bash
kubectl config set-context localhost --cluster localhost
```

- Expected output

```bash
Context "localhost" created.
```

### Set the current context to `localhost`

- Command in the `local` terminal

```bash
kubectl config use-context localhost
```

- Expected output

```bash
Switched to context "localhost".
```

### Check the cluster `ConfigMaps` with `kubectl`

- Command in the `local` terminal

```bash
kubectl get ConfigMaps
```

- Expected output

```
NAME       DATA   AGE
hello-cm   1      2m4s
```

### Inspect the `hello-cm` `ConfigMap` with `kubectl` as `json`

- Command in the `local` terminal

```bash
kubectl get ConfigMaps/hello-cm -o json
```

- Expected output

```json
{
  "apiVersion": "v1",
  "data": {
    "GREETING": "Hello folks"
  },
  "kind": "ConfigMap",
  "metadata": {
    "creationTimestamp": "2019-09-14T23:12:23Z",
    "name": "hello-cm",
    "namespace": "default",
    "resourceVersion": "46",
    "selfLink": "/api/v1/namespaces/default/configmaps/hello-cm",
    "uid": "31eaa222-061a-4b5f-95cd-fe163a9eb2e7"
  }
}
```

- Command in the `local` terminal

```bash
kubectl describe ConfigMaps/hello-cm
```

- Expected output

```yaml
Name:         hello-cm
Namespace:    default
Labels:       <none>
Annotations:  <none>

Data
====
GREETING:
----
Hello folks
Events:  <none>
```

> ## **Open a new terminal named `watcher`**

### Watch the cluster changes

- Command in the `watcher` terminal

Leave it running in the background.

```bash
watch -n2 kubectl get all
```

- Expected output

```
Every 5.0s: kubectl get all                                            alloy: Tue Oct 19 01:33:18 2021

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.0.0.1     <none>        443/TCP   49m   <none>
```

## Create a `Deployment` object

This time, we will use a `json` file instead of adding the object spec inline:

[hello-dep.json](hello-manifests/hello-dep.json)

```json
{
  "apiVersion": "apps/v1",
  "kind": "Deployment",
  "metadata": {
    "name": "hello-dep",
    "labels": {
      "app": "hello"
    }
  },
  "spec": {
    "replicas": 3,
    "selector": {
      "matchLabels": {
        "app": "hello"
      }
    },
    "template": {
      "metadata": {
        "labels": {
          "app": "hello"
        }
      },
      "spec": {
        "containers": [
          {
            "name": "nginx",
            "image": "nginx",
            "volumeMounts": [
              {
                "name": "html",
                "mountPath": "/var/www/html"
              }
            ],
            "resources": {
              "requests": {
                "cpu": "50m",
                "memory": "32Mi"
              },
              "limits": {
                "cpu": "150m",
                "memory": "32Mi"
              }
            }
          },
          {
            "name": "echo",
            "image": "alpine",
            "command": ["/bin/sh", "-c"],
            "args": [
              "while true; do echo $GREETING from $HOSTNAME at `date` | tee -a /var/www/html/index.html; sleep 10; done;"
            ],
            "envFrom": [
              {
                "configMapRef": {
                  "name": "hello-cm"
                }
              }
            ],
            "volumeMounts": [
              {
                "name": "html",
                "mountPath": "/var/www/html"
              }
            ],
            "resources": {
              "requests": {
                "cpu": "25m",
                "memory": "32Mi"
              },
              "limits": {
                "cpu": "50m",
                "memory": "32Mi"
              }
            }
          }
        ],
        "volumes": [
          {
            "name": "html"
          }
        ]
      }
    }
  }
}
```

The deployment is quite complete:

- Two containers, one running `nginx` and the other writing the `index.html` file with `echo`.
- A shared volume where the `index.html` will be stored and accessed by both.
- An environment provided by the `hello-cm` configmap, with the `GREETING`.
- The resource and limits specifications.

The resulting `Pod` will listen HTTP requests on `:80`, writing the a message with:

- The `GREETING` defined in the `ConfigMap`
- The `hostname` of the `Pod`
- The `timestamp` of the last `index.html` generation

### Create the `hello-dep.json` deployment with `curl` in `api/v1/namespaces/default/deployments`

- Command in the `local` terminal

```bash
curl -sqL \
  -X POST \
  -H "Content-Type: application/json" \
  -d @hello-manifests/hello-dep.json \
  http://localhost:8080/api/v1/namespaces/default/deployments
```

- Expected output

The expected result is a `404 NotFound` as the `deployments` `Kind` is in the `apps` API Group.

```json
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "the server could not find the requested resource",
  "reason": "NotFound",
  "details": {},
  "code": 404
}
```

### Create the `hello-dep.json` deployment with `curl` in `apis/apps/v1/namespaces/default/deployments`

- Command in the `local` terminal

```bash
curl -sqL \
  -X POST \
  -H "Content-Type: application/json" \
  -d @hello-manifests/hello-dep.json \
  http://localhost:8080/apis/apps/v1/namespaces/default/deployments
```

- Expected output

A `201 Created` response with the Object JSON definition.

```
*   Trying ::1...
* TCP_NODELAY set
* Connected to localhost (::1) port 8080 (#0)
> POST /apis/apps/v1/namespaces/default/deployments HTTP/1.1
> Host: localhost:8080
> User-Agent: curl/7.54.0
> Accept: */*
> Content-Type: application/json
> Content-Length: 1807
> Expect: 100-continue
>
< HTTP/1.1 100 Continue
* We are completely uploaded and fine
< HTTP/1.1 201 Created
< Cache-Control: no-cache, private
< Content-Type: application/json
< Date: Sat, 14 Sep 2019 23:30:01 GMT
< Transfer-Encoding: chunked
<
{
  "kind": "Deployment",
  "apiVersion": "apps/v1",
  "metadata": {
    "name": "hello-dep",
    "namespace": "default",
    "selfLink": "/apis/apps/v1/namespaces/default/deployments/hello-dep",
    "uid": "df46b275-6072-4ff4-9347-8431806a6d8f",
    "resourceVersion": "146",
    "generation": 1,
    "creationTimestamp": "2019-09-14T23:30:01Z",
    "labels": {
      "app": "hello"
    }
  },
  "spec": {
    "replicas": 3,
    "selector": {
      "matchLabels": {
        "app": "hello"
      }
    },
    "template": {
      "metadata": {
        "creationTimestamp": null,
        "labels": {
          "app": "hello"
        }
      },
      "spec": {
        "volumes": [
          {
            "name": "html",
            "emptyDir": {

            }
          }
        ],
        "containers": [
          {
            "name": "nginx",
            "image": "nginx",
            "resources": {
              "limits": {
                "cpu": "150m",
                "memory": "32Mi"
              },
              "requests": {
                "cpu": "50m",
                "memory": "32Mi"
              }
            },
            "volumeMounts": [
              {
                "name": "html",
                "mountPath": "/var/www/html"
              }
            ],
            "terminationMessagePath": "/dev/termination-log",
            "terminationMessagePolicy": "File",
            "imagePullPolicy": "Always"
          },
          {
            "name": "echo",
            "image": "alpine",
            "command": [
              "/bin/sh",
              "-c"
            ],
            "args": [
              "while true; do echo $GREETING from $HOSTNAME at `date` | tee -a /var/www/html/index.html; sleep 10; done;"
            ],
            "envFrom": [
              {
                "configMapRef": {
                  "name": "hello-cm"
                }
              }
            ],
            "resources": {
              "limits": {
                "cpu": "50m",
                "memory": "32Mi"
              },
              "requests": {
                "cpu": "25m",
                "memory": "32Mi"
              }
            },
            "volumeMounts": [
              {
                "name": "html",
                "mountPath": "/var/www/html"
              }
            ],
            "terminationMessagePath": "/dev/termination-log",
            "terminationMessagePolicy": "File",
            "imagePullPolicy": "Always"
          }
        ],
        "restartPolicy": "Always",
        "terminationGracePeriodSeconds": 30,
        "dnsPolicy": "ClusterFirst",
        "securityContext": {

        },
        "schedulerName": "default-scheduler"
      }
    },
    "strategy": {
      "type": "RollingUpdate",
      "rollingUpdate": {
        "maxUnavailable": "25%",
        "maxSurge": "25%"
      }
    },
    "revisionHistoryLimit": 10,
    "progressDeadlineSeconds": 600
  },
  "status": {

  }
}
```

- Expected output in the `kube-apisever` logs

```
I0914 23:30:01.843124   27680 httplog.go:90] POST /apis/apps/v1/namespaces/default/deployments: (60.147713ms) 201 [curl/7.54.0 127.0.0.1:32950]
```

- Expected output in the `etcd` logs

```
2019-09-14 23:30:01.837479 D | etcdserver/api/v3rpc: start time = 2019-09-14 23:30:01.837108868 +0000 UTC m=+952.411891796, time spent = 325.723µs, remote = 127.0.0.1:41562, response type = /etcdserverpb.KV/Txn, request count = 1, request size = 841, response count = 0, response size = 40, request content = compare:<target:MOD key:"/registry/deployments/default/hello-dep" mod_revision:0 > success:<request_put:<key:"/registry/deployments/default/hello-dep" value_size:794 >> failure:<>
```

### Check the deployment in `etcd`

- Command in the `local` or `instance` terminal

```bash
etcdctl get /registry/deployments --prefix --keys-only
```

- Expected value in the `etcd` directory

```
/registry/deployments/default/hello-dep
```

- Command in the `local` or `instance` terminal

```bash
etcdctl get /registry/deployments/default/hello-dep -w json
```

- Expected value in the `etcd` key

```json
{
  "header": {
    "cluster_id": 14841639068965180000,
    "member_id": 10276657743932975000,
    "revision": 151,
    "raft_term": 4
  },
  "kvs": [
    {
      "key": "L3JlZ2lzdHJ5L2RlcGxveW1lbnRzL2RlZmF1bHQvaGVsbG8tZGVw",
      "create_revision": 146,
      "mod_revision": 146,
      "version": 1,
      "value": "azhzAAoVCgdhcHBzL3YxEgpEZXBsb3ltZW50EvgFClwKCWhlbGxvLWRlcBIAGgdkZWZhdWx0IgAqJGRmNDZiMjc1LTYwNzItNGZmNC05MzQ3LTg0MzE4MDZhNmQ4ZjIAOAFCCAj57/XrBRAAWgwKA2FwcBIFaGVsbG96ABKJBQgDEg4KDAoDYXBwEgVoZWxsbxrCBAogCgASABoAIgAqADIAOABCAFoMCgNhcHASBWhlbGxvegASnQQKDAoEaHRtbBIEEgIKABKeAQoFbmdpbngSBW5naW54KgBCQQoNCgNjcHUSBgoEMTUwbQoQCgZtZW1vcnkSBgoEMzJNaRIMCgNjcHUSBQoDNTBtEhAKBm1lbW9yeRIGCgQzMk1pShsKBGh0bWwQABoNL3Zhci93d3cvaHRtbCIAMgBqFC9kZXYvdGVybWluYXRpb24tbG9ncgZBbHdheXOAAQCIAQCQAQCiAQRGaWxlEqgCCgRlY2hvEgZhbHBpbmUaBy9iaW4vc2gaAi1jIml3aGlsZSB0cnVlOyBkbyBlY2hvICRHUkVFVElORyBmcm9tICRIT1NUTkFNRSBhdCBgZGF0ZWAgfCB0ZWUgLWEgL3Zhci93d3cvaHRtbC9pbmRleC5odG1sOyBzbGVlcCAxMDsgZG9uZTsqAEJACgwKA2NwdRIFCgM1MG0KEAoGbWVtb3J5EgYKBDMyTWkSDAoDY3B1EgUKAzI1bRIQCgZtZW1vcnkSBgoEMzJNaUobCgRodG1sEAAaDS92YXIvd3d3L2h0bWwiADIAahQvZGV2L3Rlcm1pbmF0aW9uLWxvZ3IGQWx3YXlzgAEAiAEAkAEAmgEQCgASDAoKCghoZWxsby1jbaIBBEZpbGUaBkFsd2F5cyAeMgxDbHVzdGVyRmlyc3RCAEoAUgBYAGAAaAByAIIBAIoBAJoBEWRlZmF1bHQtc2NoZWR1bGVywgEAIicKDVJvbGxpbmdVcGRhdGUSFgoJCAEQABoDMjUlEgkIARAAGgMyNSUoADAKOABI2AQaDAgAEAAYACAAKAA4ABoAIgA="
    }
  ],
  "count": 1
}
```

### Check the deployment with `kubectl`

- Command in the `local` terminal

```bash
kubectl get deployments
```

- Expected output

```
NAME        READY   UP-TO-DATE   AVAILABLE   AGE
hello-dep   0/3     0            0           6m45s
```

### Check if there is any differences between the deployed with `curl` and the `kubectl` `yaml` version

- Command in the `local` terminal

```bash
kubectl diff -f hello-manifests/hello-dep.yml
```

- Expected output

To show the changes, we introduced an `annotation` in the `yaml` version. The rest of the file is identical.
A new version, increases the `generation` field that tracks the revision of the object.

```
diff -u -N /var/folders/f6/n_k4yjzd10970w35zw9kj1t40000gn/T/LIVE-509440485/apps.v1.Deployment.default.hello-dep /var/folders/f6/n_k4yjzd10970w35zw9kj1t40000gn/T/MERGED-777647616/apps.v1.Deployment.default.hello-dep
--- /var/folders/f6/n_k4yjzd10970w35zw9kj1t40000gn/T/LIVE-509440485/apps.v1.Deployment.default.hello-dep	2019-09-15 01:51:37.000000000 +0200
+++ /var/folders/f6/n_k4yjzd10970w35zw9kj1t40000gn/T/MERGED-777647616/apps.v1.Deployment.default.hello-dep	2019-09-15 01:51:37.000000000 +0200
@@ -1,8 +1,10 @@
 apiVersion: apps/v1
 kind: Deployment
 metadata:
+  annotations:
+    notes: This annotation is intentional to show the `diff` result.
   creationTimestamp: "2019-09-14T23:49:04Z"
-  generation: 1
+  generation: 2
   labels:
     app: hello
   name: hello-dep
exit status 1
```

### Check the `ReplicaSets` generated by the `Deployment`

Deployment is a Kubernetes Object that manages `ReplicaSets`.
For each `Deployment` `template` change, it will create new `ReplicaSet` with the `PodTemplate`.
Each `ReplicaSet`, will create a set of `Pods` replicas matching the `PodTemplate` and ensuring the number of `Replicas` desired is always running.

- Command in the `local` terminal

```bash
kubectl get ReplicaSets
```

- Expected output

But at this point, there should'nt be any ReplicaSet created.

```
No resources found.
```

### Check `all` the cluster resources

- Command in the `local` terminal

```bash
kubectl get all -o wide
```

- Expected output

Only the `kubernetes` service and the `hello-dep` should be listed in the output. (The `ConfigMaps` are not shown in this list.)

```
NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE   SELECTOR
service/kubernetes   ClusterIP   10.0.0.1     <none>        443/TCP   49m   <none>


NAME                        READY   UP-TO-DATE   AVAILABLE   AGE   CONTAINERS   IMAGES         SELECTOR
deployment.apps/hello-dep   0/3     0            0           12m   nginx,echo   nginx,alpine   app=hello
```

---

**What is happening? Why the `ReplicaSets` are not being created?**

---

```
####################################################
#############        controllers        ############
####################################################
```

---

## Third component: kube-controller-manager

### Start the `kube-controller-manager`

> ## **Open a new terminal named `controller`**

SSH into the instance.

- Command in the `controller` terminal

```bash
ssh $(tf output -raw ssh_host)
```

Before starting the `kube-controller-manager`, some certificates are required.
Generate the all certificates using `kubeadm`, out of the scope of this talk.

- Command in the `controller` terminal

```bash
sudo ~/kubernetes/server/bin/kubeadm init phase certs all
```

- Expected output

```
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [ip-10-0-1-69 kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.0.1.69]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [ip-10-0-1-69 localhost] and IPs [10.0.1.69 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [ip-10-0-1-69 localhost] and IPs [10.0.1.69 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
```

And now start the `kube-controller-manager` using the private key generated by `kubeadm`.

- Command in the `controller` terminal. Ensure the watch console is visible.

```bash
sudo ~/kubernetes/server/bin/kube-controller-manager --master localhost:8080 --service-account-private-key-file /etc/kubernetes/pki/sa.key --v 5
```

- Expected output from the previous step watch

With the `controllers` up, the `Deployment` and `ReplicaSets` should work as expected, as the controller will starts working on achieving the **desired state**.

```
Every 1.0s: ./kubectl get all                                                 ip-10-0-1-135: Sun Sep 15 00:17:32 2019

NAME                             READY   STATUS    RESTARTS   AGE
pod/hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          9m40s
pod/hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          9m40s
pod/hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          9m40s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.0.0.1     <none>        443/TCP   65m

NAME                        READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/hello-dep   0/3     3            0           28m

NAME                                   DESIRED   CURRENT   READY   AGE
replicaset.apps/hello-dep-758fcd6b44   3         3         0       9m41s

```

- Expected output: `kube-controller-manager` starts up.

```
I0915 00:07:49.278109   31980 flags.go:33] FLAG: --add-dir-header="false"
I0915 00:07:49.278178   31980 flags.go:33] FLAG: --address="0.0.0.0"
I0915 00:07:49.278185   31980 flags.go:33] FLAG: --allocate-node-cidrs="false"
I0915 00:07:49.278205   31980 flags.go:33] FLAG: --allow-untagged-cloud="false"
I0915 00:07:49.278220   31980 flags.go:33] FLAG: --alsologtostderr="false"
I0915 00:07:49.278227   31980 flags.go:33] FLAG: --attach-detach-reconcile-sync-period="1m0s"
I0915 00:07:49.278236   31980 flags.go:33] FLAG: --authentication-kubeconfig=""
I0915 00:07:49.278252   31980 flags.go:33] FLAG: --authentication-skip-lookup="false"
I0915 00:07:49.278267   31980 flags.go:33] FLAG: --authentication-token-webhook-cache-ttl="10s"
I0915 00:07:49.278281   31980 flags.go:33] FLAG: --authentication-tolerate-lookup-failure="false"
I0915 00:07:49.278296   31980 flags.go:33] FLAG: --authorization-always-allow-paths="[/healthz]"
I0915 00:07:49.278305   31980 flags.go:33] FLAG: --authorization-kubeconfig=""
I0915 00:07:49.278311   31980 flags.go:33] FLAG: --authorization-webhook-cache-authorized-ttl="10s"
I0915 00:07:49.278326   31980 flags.go:33] FLAG: --authorization-webhook-cache-unauthorized-ttl="10s"
I0915 00:07:49.278341   31980 flags.go:33] FLAG: --bind-address="0.0.0.0"
...
I0915 00:07:50.235580   31980 controllermanager.go:161] Version: v1.16.0-rc.2
I0915 00:07:50.235653   31980 healthz.go:123] Installing health checkers for (/healthz): "leaderElection"
I0915 00:07:50.236188   31980 secure_serving.go:123] Serving securely on [::]:10257
I0915 00:07:50.236229   31980 healthz.go:123] Installing health checkers for (/healthz): "leaderElection"
I0915 00:07:50.236737   31980 deprecated_insecure_serving.go:53] Serving insecurely on [::]:10252
I0915 00:07:50.236802   31980 leaderelection.go:241] attempting to acquire leader lease  kube-system/kube-controller-manager...
...
```

- Expected output: `kube-controller-manager`: The `deployment_controller.go` discovers `hello-dep` and starts working to accomplish the desired state `Adding deployment hello-dep`:

```
...
I0915 00:07:51.085679   31980 deployment_controller.go:168] Adding deployment hello-dep
I0915 00:07:51.085706   31980 graph_builder.go:549] GraphBuilder process object: apps/v1/Deployment, namespace default, name hello-dep, uid 112b3337-df00-4c8e-b099-5b83159179f9, event type add
I0915 00:07:51.663701   31980 deployment_controller.go:564] Started syncing deployment "default/hello-dep" (2019-09-15 00:07:51.663686717 +0000 UTC m=+2.457947344)
...
```

- Expected output: `kube-controller-manager`: The `deployment_controller.go` creates a `ReplicaSet` with the `PodTemplate` and the desired number of `Replicas`.

```
...
I0915 00:07:51.664155   31980 deployment_util.go:259] Updating replica set "hello-dep-758fcd6b44" revision to 1
I0915 00:07:51.667422   31980 deployment_controller.go:214] ReplicaSet hello-dep-758fcd6b44 added.
I0915 00:07:51.667446   31980 graph_builder.go:549] GraphBuilder process object: apps/v1/ReplicaSet, namespace default, name hello-dep-758fcd6b44, uid b7100942-125b-4374-961c-adcd8c7d7694, event type add
I0915 00:07:51.667462   31980 controller_utils.go:201] Controller default/hello-dep-758fcd6b44 either never recorded expectations, or the ttl expired.
I0915 00:07:51.667545   31980 controller_utils.go:218] Setting expectations &controller.ControlleeExpectations{add:3, del:0, key:"default/hello-dep-758fcd6b44", timestamp:time.Time{wall:0xbf577e15e7c9dd16, ext:2461801415, loc:(*time.Location)(0x7777000)}}
I0915 00:07:51.667616   31980 replica_set.go:477] Too few replicas for ReplicaSet default/hello-dep-758fcd6b44, need 3, creating 3
I0915 00:07:51.668007   31980 event.go:255] Event(v1.ObjectReference{Kind:"Deployment", Namespace:"default", Name:"hello-dep", UID:"112b3337-df00-4c8e-b099-5b83159179f9", APIVersion:"apps/v1", ResourceVersion:"254", FieldPath:""}): type: 'Normal' reason: 'ScalingReplicaSet' Scaled up replica set hello-dep-758fcd6b44 to 3
...
```

- Expected output: `kube-controller-manager`: The `replica_set.go` starts creating new `Pods` to match the `ReplicaSet` desired state.

```
I0915 00:07:52.675172   31980 controller_utils.go:588] Controller hello-dep-758fcd6b44 created pod hello-dep-758fcd6b44-w8ctt
I0915 00:07:52.675333   31980 event.go:255] Event(v1.ObjectReference{Kind:"ReplicaSet", Namespace:"default", Name:"hello-dep-758fcd6b44", UID:"b7100942-125b-4374-961c-adcd8c7d7694", APIVersion:"apps/v1", ResourceVersion:"374", FieldPath:""}): type: 'Normal' reason: 'SuccessfulCreate' Created pod: hello-dep-758fcd6b44-w8ctt
I0915 00:07:52.675480   31980 disruption.go:373] addPod called on pod "hello-dep-758fcd6b44-w8ctt"
I0915 00:07:52.675519   31980 graph_builder.go:549] GraphBuilder process object: v1/Pod, namespace default, name hello-dep-758fcd6b44-w8ctt, uid ab578bcd-1fec-448c-bcbc-7c826324bec8, event type add
I0915 00:07:52.675537   31980 disruption.go:448] No PodDisruptionBudgets found for pod hello-dep-758fcd6b44-w8ctt, PodDisruptionBudget controller will avoid syncing.
I0915 00:07:52.675600   31980 disruption.go:376] No matching pdb for pod "hello-dep-758fcd6b44-w8ctt"
I0915 00:07:52.675658   31980 taint_manager.go:398] Noticed pod update: types.NamespacedName{Namespace:"default", Name:"hello-dep-758fcd6b44-w8ctt"}
I0915 00:07:52.675568   31980 pvc_protection_controller.go:342] Enqueuing PVCs for Pod default/hello-dep-758fcd6b44-w8ctt (UID=ab578bcd-1fec-448c-bcbc-7c826324bec8)
I0915 00:07:52.675494   31980 replica_set.go:275] Pod hello-dep-758fcd6b44-w8ctt created: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"hello-dep-758fcd6b44-w8ctt", GenerateName:"hello-dep-758fcd6b44-", Namespace:"default", SelfLink:"/api/v1/namespaces/default/pods/hello-dep-758fcd6b44-w8ctt", UID:"ab578bcd-1fec-448c-bcbc-7c826324bec8", ResourceVersion:"390", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63704102872, loc:(*time.Location)(0x7777000)}},...
```

### Review the status of the `hello-dep` `ReplicaSets` after starting the `kube-controller-manager`

- Command in the `local` terminal

```bash
kubectl get ReplicaSets -o wide
```

- Expected output

```
NAME                   DESIRED   CURRENT   READY   AGE   CONTAINERS   IMAGES         SELECTOR
hello-dep-758fcd6b44   3         3         0       29m   nginx,echo   nginx,alpine   app=hello,pod-template-hash=758fcd6b44
```

### Review the status of the `hello-dep` `Pods`after staring the `kube-controller-manager`

- Command in the `local` terminal

```bash
kubectl get pods -o wide -w
```

- Expected output

The `Pods` are stuck in `Pending` state.

```
NAME                         READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
```

- Command in the `local` terminal

```bash
kubectl describe pods
```

- Expected output

The `Pods` exist in the `etcd` but are not being scheduled.

```
Name:           hello-dep-758fcd6b44-w8ctt
Namespace:      default
Priority:       0
Node:           <none>
Labels:         app=hello
                pod-template-hash=758fcd6b44
Annotations:    <none>
Status:         Pending
IP:
Controlled By:  ReplicaSet/hello-dep-758fcd6b44
Containers:
  nginx:
    Image:      nginx
    Port:       <none>
    Host Port:  <none>
    Limits:
      cpu:     150m
      memory:  32Mi
    Requests:
      cpu:        50m
      memory:     32Mi
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fkl4j (ro)
      /var/www/html from html (rw)
  echo:
    Image:      alpine
    Port:       <none>
    Host Port:  <none>
    Command:
      /bin/sh
      -c
    Args:
      while true; do echo $GREETING from $HOSTNAME at `date` | tee -a /var/www/html/index.html; sleep 10; done;
    Limits:
      cpu:     50m
      memory:  32Mi
    Requests:
      cpu:     25m
      memory:  32Mi
    Environment Variables from:
      hello-cm    ConfigMap  Optional: false
    Environment:  <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fkl4j (ro)
      /var/www/html from html (rw)
Volumes:
  html:
    Type:       EmptyDir (a temporary directory that shares a pod's lifetime)
    Medium:
    SizeLimit:  <unset>
  default-token-fkl4j:
    Type:        Secret (a volume populated by a Secret)
    SecretName:  default-token-fkl4j
    Optional:    false
QoS Class:       Burstable
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:          <none>
```

---

```
####################################################
#############          Scheduler        ############
####################################################
```

---

## Forth component: `kube-scheduler`

### Watch the `Pods`

Leave this watch in the background.

- Command in the `local` terminal

```bash
kubectl get pods -o wide -w
```

- Expected output

```
NAME                         READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
```

### Start the `kube-scheduler`

> ## **Open a new terminal named `scheduler`**

SSH into the instance.

- Command in the `scheduler` terminal

```bash
ssh $(tf output -raw ssh_host)
```

- Command in the `scheduler` terminal

```bash
sudo ~/kubernetes/server/bin/kube-scheduler --master localhost:8080 --v 3
```

- Expected output: `kube-scheduler` startup

```
I0915 00:44:28.912928   21416 flags.go:33] FLAG: --add-dir-header="false"
I0915 00:44:28.912989   21416 flags.go:33] FLAG: --address="0.0.0.0"
I0915 00:44:28.912995   21416 flags.go:33] FLAG: --algorithm-provider=""
I0915 00:44:28.912999   21416 flags.go:33] FLAG: --alsologtostderr="false"
I0915 00:44:28.913004   21416 flags.go:33] FLAG: --authentication-kubeconfig=""
I0915 00:44:28.913007   21416 flags.go:33] FLAG: --authentication-skip-lookup="false"
I0915 00:44:28.913013   21416 flags.go:33] FLAG: --authentication-token-webhook-cache-ttl="10s"
I0915 00:44:28.913018   21416 flags.go:33] FLAG: --authentication-tolerate-lookup-failure="true"
I0915 00:44:28.913022   21416 flags.go:33] FLAG: --authorization-always-allow-paths="[/healthz]"
I0915 00:44:28.913030   21416 flags.go:33] FLAG: --authorization-kubeconfig=""
I0915 00:44:28.913034   21416 flags.go:33] FLAG: --authorization-webhook-cache-authorized-ttl="10s"
I0915 00:44:28.913038   21416 flags.go:33] FLAG: --authorization-webhook-cache-unauthorized-ttl="10s"
I0915 00:44:28.913042   21416 flags.go:33] FLAG: --bind-address="0.0.0.0"
I0915 00:44:28.913047   21416 flags.go:33] FLAG: --cert-dir=""
...
I0915 00:44:29.808968   21416 server.go:143] Version: v1.16.0-rc.2
I0915 00:44:29.809056   21416 defaults.go:91] TaintNodesByCondition is enabled, PodToleratesNodeTaints predicate is mandatory
I0915 00:44:29.809080   21416 server.go:162] Starting Kubernetes Scheduler version v1.16.0-rc.2
I0915 00:44:29.809335   21416 factory.go:294] Creating scheduler from algorithm provider 'DefaultProvider'
I0915 00:44:29.809367   21416 factory.go:382] Creating scheduler with fit predicates 'map[CheckNodeUnschedulable:{} CheckVolumeBinding:{} GeneralPredicates:{} MatchInterPodAffinity:{} MaxAzureDiskVolumeCount:{} MaxCSIVolumeCountPred:{} MaxEBSVolumeCount:{} MaxGCEPDVolumeCount:{} NoDiskConflict:{} NoVolumeZoneConflict:{} PodToleratesNodeTaints:{}]' and priority functions 'map[BalancedResourceAllocation:{} ImageLocalityPriority:{} InterPodAffinityPriority:{} LeastRequestedPriority:{} NodeAffinityPriority:{} NodePreferAvoidPodsPriority:{} SelectorSpreadPriority:{} TaintTolerationPriority:{}]'
...
```

- Expected output: `kube-scheduler` starts working on scheduing the `Pods`:

But there are no `Nodes` availables.

```
I0915 00:44:30.921341   21416 scheduler.go:530] Attempting to schedule pod: default/hello-dep-758fcd6b44-w8ctt
I0915 00:44:30.921398   21416 factory.go:542] Unable to schedule default/hello-dep-758fcd6b44-w8ctt: no nodes are registered to the cluster; waiting
I0915 00:44:30.921444   21416 factory.go:619] Updating pod condition for default/hello-dep-758fcd6b44-w8ctt to (PodScheduled==False, Reason=Unschedulable)
E0915 00:44:30.924355   21416 scheduler.go:559] error selecting node for pod: no nodes available to schedule pods
I0915 00:44:30.924565   21416 scheduler.go:530] Attempting to schedule pod: default/hello-dep-758fcd6b44-xtnjc
I0915 00:44:30.924625   21416 factory.go:542] Unable to schedule default/hello-dep-758fcd6b44-xtnjc: no nodes are registered to the cluster; waiting
I0915 00:44:30.924678   21416 factory.go:619] Updating pod condition for default/hello-dep-758fcd6b44-xtnjc to (PodScheduled==False, Reason=Unschedulable)
E0915 00:44:30.927649   21416 factory.go:585] pod is already present in the activeQ
E0915 00:44:30.927648   21416 scheduler.go:559] error selecting node for pod: no nodes available to schedule pods
I0915 00:44:30.927826   21416 scheduler.go:530] Attempting to schedule pod: default/hello-dep-758fcd6b44-t2n9n
I0915 00:44:30.927871   21416 factory.go:542] Unable to schedule default/hello-dep-758fcd6b44-t2n9n: no nodes are registered to the cluster; waiting
I0915 00:44:30.927906   21416 factory.go:619] Updating pod condition for default/hello-dep-758fcd6b44-t2n9n to (PodScheduled==False, Reason=Unschedulable)
E0915 00:44:30.930187   21416 scheduler.go:559] error selecting node for pod: no nodes available to schedule pods
```

- Expeted output: `kubectl get pods -o wide -w` status update with some events

```
NAME                         READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          36m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          36m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          36m   <none>   <none>   <none>           <none>
```

### Check `Pods` status

- Command in the `local` terminal

```bash
kubectl describe pods
```

- Expected output

The `Pods` are still stuck in pending due to the lack of nodes: `Warning  FailedScheduling  <unknown>  default-scheduler  no nodes available to schedule pods`.

```
Name:           hello-dep-758fcd6b44-t2n9n
Namespace:      default
Priority:       0
Node:           <none>
Labels:         app=hello
                pod-template-hash=758fcd6b44
Annotations:    <none>
Status:         Pending
IP:
Controlled By:  ReplicaSet/hello-dep-758fcd6b44
Containers:
  nginx:
...
Node-Selectors:  <none>
Tolerations:     node.kubernetes.io/not-ready:NoExecute for 300s
                 node.kubernetes.io/unreachable:NoExecute for 300s
Events:
  Type     Reason            Age        From               Message
  ----     ------            ----       ----               -------
  Warning  FailedScheduling  <unknown>  default-scheduler  no nodes available to schedule pods
  Warning  FailedScheduling  <unknown>  default-scheduler  no nodes available to schedule pods
...
```

### Check the nodes

- Command in the `local` terminal

```bash
kubectl get nodes
```

- Expected output

There are no nodes, so the output should be an empty set. We need a node.

```
No resources found.
```

---

```
####################################################
#############          kubelet          ############
####################################################
```

---

## Fifth component: `kubelet`

> ## **Open a new terminal named `kubelet`**

SSH into the instance.

- Command in the `kubelet` terminal

```bash
ssh $(tf output -raw ssh_host)
```

### Create a .kube/config file for kubelet

To make the interaction more user friendly, we can use the `kubectl` command line CLI.
Use it locally thanks to the SSH tunnel, or with `~/kubernetes/server/bin/kubectl` at the `instance` terminal.

To make the commands friendly to both scenarios, install `kubectl` in the EC2 instance `/usr/local/bin` path using:

- Command in the `kubelet` terminal

```
sudo install ~/kubernetes/server/bin/kubectl /usr/local/bin/;
```

And then repeat the same commands to setup the `.kube/config` file.

- Command in the `kubelet` terminal

```
kubectl config set-cluster local --server localhost:8080;
kubectl config set-context local --cluster local;
kubectl config use-context local;
kubectl cluster-info;
```

### Check the resulting .kube/config file

- Command

```bash
cat ~/.kube/config
```

- Expected output

```yaml
apiVersion: v1
clusters:
  - cluster:
      server: localhost:8080
    name: localhost
contexts:
  - context:
      cluster: localhost
      user: ""
    name: localhost
current-context: localhost
kind: Config
preferences: {}
users: []
```

- Command

```bash
sudo ~/kubernetes/server/bin/kubelet --register-node --kubeconfig ~/.kube/config
```

Something missing?

```
sudo service docker start
```

- Command

```bash
sudo ~/kubernetes/server/bin/kubelet --register-node --kubeconfig ~/.kube/config
```

- Expected output `kubelet` start up

```
I0915 00:54:20.740880   21441 server.go:410] Version: v1.16.0-rc.2
I0915 00:54:20.741137   21441 plugins.go:100] No cloud provider specified.
W0915 00:54:20.743480   21441 container_manager_linux.go:842] CPUAccounting not enabled for pid: 21441
W0915 00:54:20.743510   21441 container_manager_linux.go:845] MemoryAccounting not enabled for pid: 21441
I0915 00:54:20.792474   21441 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /
I0915 00:54:20.793170   21441 container_manager_linux.go:265] container manager verified user specified cgroup-root exists: []
...
I0915 00:54:20.856554   21441 status_manager.go:156] Starting to sync pod status with apiserver
I0915 00:54:20.856582   21441 server.go:354] Adding debug handlers to kubelet server.
I0915 00:54:20.856567   21441 volume_manager.go:249] Starting Kubelet Volume Manager
I0915 00:54:20.856624   21441 kubelet.go:1822] Starting kubelet main sync loop.
I0915 00:54:20.856691   21441 kubelet.go:1839] skipping pod synchronization - [container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]
I0915 00:54:20.860228   21441 desired_state_of_world_populator.go:131] Desired state populator starts to run
...
```

If you see some errors like:

```
Failed to get system container stats
```

Use:

```
sudo ~/kubernetes/server/bin/kubelet --register-node --kubeconfig ~/.kube/config \
 --runtime-cgroups=/systemd/system.slice --kubelet-cgroups=/systemd/system.slice
```

- Expected output in the `kube-scheduler` logs

`kube-scheduler` now can `bind` the `Pending` `Pods` to the new node.

```
I0915 00:58:59.819479   21416 factory.go:619] Updating pod condition for default/hello-dep-758fcd6b44-xtnjc to (PodScheduled==False, Reason=Unschedulable)
I0915 00:58:59.820922   21416 generic_scheduler.go:337] Preemption will not help schedule pod default/hello-dep-758fcd6b44-xtnjc on any node.
I0915 01:00:19.181408   21416 scheduler.go:530] Attempting to schedule pod: default/hello-dep-758fcd6b44-t2n9n
I0915 01:00:19.181693   21416 factory.go:610] Attempting to bind hello-dep-758fcd6b44-t2n9n to ip-10-0-1-135
I0915 01:00:19.181760   21416 scheduler.go:530] Attempting to schedule pod: default/hello-dep-758fcd6b44-w8ctt
I0915 01:00:19.181984   21416 factory.go:610] Attempting to bind hello-dep-758fcd6b44-w8ctt to ip-10-0-1-135
I0915 01:00:19.182007   21416 scheduler.go:530] Attempting to schedule pod: default/hello-dep-758fcd6b44-xtnjc
I0915 01:00:19.182177   21416 factory.go:610] Attempting to bind hello-dep-758fcd6b44-xtnjc to ip-10-0-1-135
I0915 01:00:19.184212   21416 scheduler.go:667] pod default/hello-dep-758fcd6b44-t2n9n is bound successfully on node "ip-10-0-1-135", 1 nodes evaluated, 1 nodes were found feasible. Bound node resource: "Capacity: CPU<8>|Memory<32665980Ki>|Pods<110>|StorageEphemeral<8065444Ki>; Allocatable: CPU<8>|Memory<32563580Ki>|Pods<110>|StorageEphemeral<7433113179>.".
I0915 01:00:19.184560   21416 scheduler.go:667] pod default/hello-dep-758fcd6b44-xtnjc is bound successfully on node "ip-10-0-1-135", 1 nodes evaluated, 1 nodes were found feasible. Bound node resource: "Capacity: CPU<8>|Memory<32665980Ki>|Pods<110>|StorageEphemeral<8065444Ki>; Allocatable: CPU<8>|Memory<32563580Ki>|Pods<110>|StorageEphemeral<7433113179>.".
I0915 01:00:19.186202   21416 scheduler.go:667] pod default/hello-dep-758fcd6b44-w8ctt is bound successfully on node "ip-10-0-1-135", 1 nodes evaluated, 1 nodes were found feasible. Bound node resource: "Capacity: CPU<8>|Memory<32665980Ki>|Pods<110>|StorageEphemeral<8065444Ki>; Allocatable: CPU<8>|Memory<32563580Ki>|Pods<110>|StorageEphemeral<7433113179>.".
```

- Expected output `kubelet` after the `kube-scheduler` `Pod` binding

kubelet is watching the `Kubernetes API` and discover that some `Pods` are binded to the node were is running and starts working with the `Container Runtime` to run the required containers.

```
I0915 00:59:50.497152   21702 reconciler.go:154] Reconciler: start to sync state
I0915 01:00:19.248126   21702 reconciler.go:207] operationExecutor.VerifyControllerAttachedVolume started for volume "html" (UniqueName: "kubernetes.io/empty-dir/4080bfc4-03b5-49c4-89ae-7c32c674a85e-html") pod "hello-dep-758fcd6b44-t2n9n" (UID: "4080bfc4-03b5-49c4-89ae-7c32c674a85e")
I0915 01:00:19.248181   21702 reconciler.go:207] operationExecutor.VerifyControllerAttachedVolume started for volume "default-token-fkl4j" (UniqueName: "kubernetes.io/secret/4080bfc4-03b5-49c4-89ae-7c32c674a85e-default-token-fkl4j") pod "hello-dep-758fcd6b44-t2n9n" (UID: "4080bfc4-03b5-49c4-89ae-7c32c674a85e")
I0915 01:00:19.248209   21702 reconciler.go:207] operationExecutor.VerifyControllerAttachedVolume started for volume "html" (UniqueName: "kubernetes.io/empty-dir/056c9b45-7514-4d79-a1fa-f37eb4b3fc93-html") pod "hello-dep-758fcd6b44-xtnjc" (UID: "056c9b45-7514-4d79-a1fa-f37eb4b3fc93")
I0915 01:00:19.248287   21702 reconciler.go:207] operationExecutor.VerifyControllerAttachedVolume started for volume "default-token-fkl4j" (UniqueName: "kubernetes.io/secret/056c9b45-7514-4d79-a1fa-f37eb4b3fc93-default-token-fkl4j") pod "hello-dep-758fcd6b44-xtnjc" (UID: "056c9b45-7514-4d79-a1fa-f37eb4b3fc93")
I0915 01:00:19.248378   21702 reconciler.go:207] operationExecutor.VerifyControllerAttachedVolume started for volume "html" (UniqueName: "kubernetes.io/empty-dir/ab578bcd-1fec-448c-bcbc-7c826324bec8-html") pod "hello-dep-758fcd6b44-w8ctt" (UID: "ab578bcd-1fec-448c-bcbc-7c826324bec8")
```

- Expected output from the nodes watch `kubectl get nodes -o wide -w`

```
ip-10-0-1-135   NotReady   <none>   0s    v1.16.0-rc.2   10.0.1.135   <none>   Ubuntu 18.04.3 LTS   4.15.0-1048-aws   docker://18.9.9
ip-10-0-1-135   Ready      <none>   1s    v1.16.0-rc.2   10.0.1.135   <none>   Ubuntu 18.04.3 LTS   4.15.0-1048-aws   docker://18.9.9
```

- Expected ouput in the pods watch `kubectl get pods -o wide -w`

```bash
kubectl get pods -o wide -w
```

```
NAME                         READY   STATUS    RESTARTS   AGE   IP       NODE     NOMINATED NODE   READINESS GATES
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          26m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          36m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          36m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          36m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          46m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          46m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          46m   <none>   <none>   <none>           <none>
hello-dep-758fcd6b44-t2n9n   0/2     Pending   0          52m   <none>   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     Pending   0          52m   <none>   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     Pending   0          52m   <none>   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-t2n9n   0/2     ContainerCreating   0          52m   <none>   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-xtnjc   0/2     ContainerCreating   0          52m   <none>   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-w8ctt   0/2     ContainerCreating   0          52m   <none>   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-t2n9n   2/2     Running             0          52m   172.17.0.2   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-xtnjc   2/2     Running             0          52m   172.17.0.3   ip-10-0-1-135   <none>           <none>
hello-dep-758fcd6b44-w8ctt   2/2     Running             0          52m   172.17.0.4   ip-10-0-1-135   <none>           <none>`
```

### Check `docker ps` to view the actual containers running

- Command in the `instance` terminal

```bash
docker ps
```

- Expected output

```
CONTAINER ID        IMAGE                  COMMAND                  CREATED              STATUS              PORTS               NAMES
733ec4871eb8        alpine                 "/bin/sh -c 'while t…"   About a minute ago   Up About a minute                       k8s_echo_hello-dep-758fcd6b44-w8ctt_default_ab578bcd-1fec-448c-bcbc-7c826324bec8_0
13a2338b4895        alpine                 "/bin/sh -c 'while t…"   About a minute ago   Up About a minute                       k8s_echo_hello-dep-758fcd6b44-xtnjc_default_056c9b45-7514-4d79-a1fa-f37eb4b3fc93_0
058e9700947d        alpine                 "/bin/sh -c 'while t…"   About a minute ago   Up About a minute                       k8s_echo_hello-dep-758fcd6b44-t2n9n_default_4080bfc4-03b5-49c4-89ae-7c32c674a85e_0
31519a6f15d2        nginx                  "nginx -g 'daemon of…"   About a minute ago   Up About a minute                       k8s_nginx_hello-dep-758fcd6b44-w8ctt_default_ab578bcd-1fec-448c-bcbc-7c826324bec8_0
41b11a7f25e1        nginx                  "nginx -g 'daemon of…"   About a minute ago   Up About a minute                       k8s_nginx_hello-dep-758fcd6b44-xtnjc_default_056c9b45-7514-4d79-a1fa-f37eb4b3fc93_0
064702fbfb75        nginx                  "nginx -g 'daemon of…"   About a minute ago   Up About a minute                       k8s_nginx_hello-dep-758fcd6b44-t2n9n_default_4080bfc4-03b5-49c4-89ae-7c32c674a85e_0
c65bdd6329d5        k8s.gcr.io/pause:3.1   "/pause"                 About a minute ago   Up About a minute                       k8s_POD_hello-dep-758fcd6b44-w8ctt_default_ab578bcd-1fec-448c-bcbc-7c826324bec8_0
15f3d15b475b        k8s.gcr.io/pause:3.1   "/pause"                 About a minute ago   Up About a minute                       k8s_POD_hello-dep-758fcd6b44-xtnjc_default_056c9b45-7514-4d79-a1fa-f37eb4b3fc93_0
47fb404ee9c2        k8s.gcr.io/pause:3.1   "/pause"                 About a minute ago   Up About a minute                       k8s_POD_hello-dep-758fcd6b44-t2n9n_default_4080bfc4-03b5-49c4-89ae-7c32c674a85e_0
```

## Expose the `Deploment` with a `Service`

- Command in the `local` terminal

```
kubectl apply -f hello-manifests/hello-svc.yml
```

- Expected output

```
service/hello created
```

- Command in the `local` terminal

```
kubectl get svc
```

```
NAME         TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
hello        ClusterIP   10.0.0.170   <none>        80/TCP    5s
kubernetes   ClusterIP   10.0.0.1     <none>        443/TCP   116m
```

- Command in the `local` terminal

```
kubectl describe svc/hello
```

- Expected output

```
Name:              hello
Namespace:         default
Labels:            <none>
Annotations:       kubectl.kubernetes.io/last-applied-configuration:
                     {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"name":"hello","namespace":"default"},"spec":{"ports":[{"port":80,"target...
Selector:          app=hello
Type:              ClusterIP
IP:                10.0.0.170
Port:              <unset>  80/TCP
TargetPort:        80/TCP
Endpoints:         <none>
Session Affinity:  None
Events:            <none>
```

## Try to connect to the service IP

- Command in the `instance` terminal

```bash
curl --connect-timeout 5 $(kubectl get svc hello -o=jsonpath='{.spec.clusterIP}')
```

- Expected output

```
curl: (28) Connection timed out after 5003 milliseconds
```

---

```
####################################################
#############        Kube-proxy         ############
####################################################
```

---

## Sixth component: `kube-proxy`

> ## **Open a new terminal named `kube-proxy`**

SSH into the instance.

- Command in the `kube-proxy` terminal to connect to the instance

```bash
ssh $(tf output -raw ssh_host)
```

- Command in the `instance` terminal

```bash
sudo iptables -L -t nat
```

- Expected output

```
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination

Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination

Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination
KUBE-POSTROUTING  all  --  anywhere             anywhere             /* kubernetes postrouting rules */

Chain DOCKER (0 references)
target     prot opt source               destination

Chain KUBE-MARK-DROP (0 references)
target     prot opt source               destination
MARK       all  --  anywhere             anywhere             MARK or 0x8000

Chain KUBE-MARK-MASQ (0 references)
target     prot opt source               destination
MARK       all  --  anywhere             anywhere             MARK or 0x4000

Chain KUBE-NODEPORTS (0 references)
target     prot opt source               destination

Chain KUBE-POSTROUTING (1 references)
target     prot opt source               destination
MASQUERADE  all  --  anywhere             anywhere             /* kubernetes service traffic requiring SNAT */ mark match 0x4000/0x4000

Chain KUBE-SEP-6SPA4RGUBMCPNL7E (0 references)
target     prot opt source               destination

Chain KUBE-SEP-IVGNBKIHSXG5MLX5 (0 references)
target     prot opt source               destination

Chain KUBE-SEP-LMO7SA7N7VN2FP4C (0 references)
target     prot opt source               destination

Chain KUBE-SEP-QEQL2SVSXQTTJNE2 (0 references)
target     prot opt source               destination

Chain KUBE-SERVICES (0 references)
target     prot opt source               destination

Chain KUBE-SVC-NPX46M4PTMTKRN6Y (0 references)
target     prot opt source               destination

Chain KUBE-SVC-TWVLBX4WCEZSIVWL (0 references)
target     prot opt source               destination
```

- Command in the `kube-proxy` terminal to start kube-proxy

```bash
sudo ~/kubernetes/server/bin/kube-proxy --master localhost:8080
```

- Expected output

```
I0915 01:25:42.369751   25440 service.go:357] Adding new service port "default/hello:" at 10.0.0.103:80/TCP
I0915 01:25:42.369811   25440 proxier.go:713] Syncing iptables rules
I0915 01:25:42.386286   25440 iptables.go:332] running iptables-save [-t filter]
I0915 01:25:42.387520   25440 iptables.go:332] running iptables-save [-t nat]
I0915 01:25:42.389039   25440 proxier.go:798] Not using `--random-fully` in the MASQUERADE rule for iptables because the local version of iptables does not support it
I0915 01:25:42.389133   25440 proxier.go:1524] Opened local port "nodePort for default/hello:" (:31890/tcp)
I0915 01:25:42.389193   25440 iptables.go:397] running iptables-restore [--noflush --counters]
I0915 01:25:42.391079   25440 proxier.go:692] syncProxyRules took 21.342451ms
I0915 01:25:42.391112   25440 bounded_frequency_runner.go:221] sync-runner: ran, next possible in 0s, periodic in 30s
```

- Command in the `kube-proxy` terminal to check the service again

```
curl --connect-timeout 5 $(kubectl get svc hello -o=jsonpath='{.spec.clusterIP}')
```

- Command in the `instance` terminal

```bash
sudo iptables -L -t nat
```

- Expected output

```bash
Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */
DOCKER     all  --  anywhere             anywhere             ADDRTYPE match dst-type LOCAL

Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination
KUBE-SERVICES  all  --  anywhere             anywhere             /* kubernetes service portals */
DOCKER     all  --  anywhere            !localhost/8          ADDRTYPE match dst-type LOCAL

Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination
KUBE-POSTROUTING  all  --  anywhere             anywhere             /* kubernetes postrouting rules */
MASQUERADE  all  --  172.17.0.0/16        anywhere

Chain DOCKER (2 references)
target     prot opt source               destination
RETURN     all  --  anywhere             anywhere

Chain KUBE-MARK-DROP (0 references)
target     prot opt source               destination
MARK       all  --  anywhere             anywhere             MARK or 0x8000

Chain KUBE-MARK-MASQ (5 references)
target     prot opt source               destination
MARK       all  --  anywhere             anywhere             MARK or 0x4000

Chain KUBE-NODEPORTS (1 references)
target     prot opt source               destination
KUBE-MARK-MASQ  tcp  --  anywhere             anywhere             /* default/hello: */ tcp dpt:31890
KUBE-SVC-TWVLBX4WCEZSIVWL  tcp  --  anywhere             anywhere             /* default/hello: */ tcp dpt:31890

Chain KUBE-POSTROUTING (1 references)
target     prot opt source               destination
MASQUERADE  all  --  anywhere             anywhere             /* kubernetes service traffic requiring SNAT */ mark match 0x4000/0x4000

Chain KUBE-SEP-SP7JBK2WW3KZSQBQ (1 references)
target     prot opt source               destination
KUBE-MARK-MASQ  all  --  ip-10-0-1-135        anywhere
DNAT       tcp  --  anywhere             anywhere             tcp to:10.0.1.135:6443

Chain KUBE-SEP-SY2PZQWZR2UT46RB (1 references)
target     prot opt source               destination
KUBE-MARK-MASQ  all  --  172.17.0.6           anywhere
DNAT       tcp  --  anywhere             anywhere             tcp to:172.17.0.6:80

Chain KUBE-SEP-TU6S3TYJDJNFJ67V (1 references)
target     prot opt source               destination
KUBE-MARK-MASQ  all  --  172.17.0.7           anywhere
DNAT       tcp  --  anywhere             anywhere             tcp to:172.17.0.7:80

Chain KUBE-SEP-YCI454ZKXCU37IFD (1 references)
target     prot opt source               destination
KUBE-MARK-MASQ  all  --  172.17.0.5           anywhere
DNAT       tcp  --  anywhere             anywhere             tcp to:172.17.0.5:80

Chain KUBE-SERVICES (2 references)
target     prot opt source               destination
KUBE-SVC-TWVLBX4WCEZSIVWL  tcp  --  anywhere             10.0.0.103           /* default/hello: cluster IP */ tcp dpt:http
KUBE-SVC-NPX46M4PTMTKRN6Y  tcp  --  anywhere             10.0.0.1             /* default/kubernetes:https cluster IP */ tcp dpt:https
KUBE-NODEPORTS  all  --  anywhere             anywhere             /* kubernetes service nodeports; NOTE: this must be the last rule in this chain */ ADDRTYPE match dst-type LOCAL

Chain KUBE-SVC-NPX46M4PTMTKRN6Y (1 references)
target     prot opt source               destination
KUBE-SEP-SP7JBK2WW3KZSQBQ  all  --  anywhere             anywhere

Chain KUBE-SVC-TWVLBX4WCEZSIVWL (2 references)
target     prot opt source               destination
KUBE-SEP-YCI454ZKXCU37IFD  all  --  anywhere             anywhere             statistic mode random probability 0.33332999982
KUBE-SEP-SY2PZQWZR2UT46RB  all  --  anywhere             anywhere             statistic mode random probability 0.50000000000
KUBE-SEP-TU6S3TYJDJNFJ67V  all  --  anywhere             anywhere   `
```

- Command in the `local` terminal to get service external endpoint

```bash
export HELLO_URL="http://$(tf output -raw public_ip):$(kubectl get svc hello -o=jsonpath='{.spec.ports[?(@.port==80)].nodePort}')" && echo ${HELLO_URL}
```

---

```
####################################################
#############         Wrapping up       ############
####################################################
```

---

## Deployment rollout

- Command in the `local` terminal

```
kubectl diff -f hello-manifests/hello-dep-fixed.yml
```

- Command in the `local` terminal

```
kubectl apply -f hello-manifests/hello-dep-fixed.yml
```

- Command in the `local` terminal

```
export HELLO_URL="http://$(tf output -raw public_ip):$(kubectl get svc hello -o=jsonpath='{.spec.ports[?(@.port==80)].nodePort}')" && echo ${HELLO_URL}
```

---

```
####################################################
#############       More Deploys!       ############
####################################################
```

## My App

```
kubectl apply -f my-app/service.yaml
```

```
k apply -f my-app/deployment-v1.yaml
```

```
export MYAPP_URL="http://$(tf output -raw public_ip):$(kubectl get svc my-app -o=jsonpath='{.spec.ports[?(@.port==80)].nodePort}')" \
  && echo ${MYAPP_URL} \
  && curl ${MYAPP_URL}
```

Leave this in a visible shell:

```
export MYAPP_URL="http://$(tf output -raw public_ip):$(kubectl get svc my-app -o=jsonpath='{.spec.ports[?(@.port==80)].nodePort}')" \
  && while sleep 0.5; do curl "${MYAPP_URL}" --connect-timeout 5; done
```

```
kubectl apply -f my-app/deployment-v2.yaml \
  && kubectl get pods -w
```

####################################################
############# Clean up ############
####################################################

````

## Guestbook

```
kubectl apply -f guestbook
```

Expected output:

```
deployment.apps/guestbook created
service/guestbook created
deployment.apps/redis-master created
service/redis-master created
deployment.apps/redis-slave created
service/redis-slave created
```

Review and use the Gestbook App:

```
export GUESTBOOK_URL="http://$(tf output -raw public_ip):$(kubectl get svc guestbook -o=jsonpath='{.spec.ports[?(@.port==80)].nodePort}')" \
  && echo ${GUESTBOOK_URL}
```

---

## Delete everything

- Command in the `local` terminal

```bash
tf destroy
````

- Expected output

```
Acquiring state lock. This may take a few moments...
data.terraform_remote_state.aws_network: Refreshing state...
module.ec2.data.aws_ami.ubuntu: Refreshing state...
module.ec2.aws_security_group.instance-sg: Refreshing state... [id=sg-00e57f209d72da0e1]
module.ec2.aws_spot_instance_request.instance: Refreshing state... [id=sir-25jg459p]
module.ec2.aws_spot_instance_request.instance: Destroying... [id=sir-25jg459p]
module.ec2.aws_spot_instance_request.instance: Still destroying... [id=sir-25jg459p, 10s elapsed]
module.ec2.aws_spot_instance_request.instance: Still destroying... [id=sir-25jg459p, 20s elapsed]
module.ec2.aws_spot_instance_request.instance: Still destroying... [id=sir-25jg459p, 30s elapsed]
module.ec2.aws_spot_instance_request.instance: Destruction complete after 30s
module.ec2.aws_security_group.instance-sg: Destroying... [id=sg-00e57f209d72da0e1]
module.ec2.aws_security_group.instance-sg: Still destroying... [id=sg-00e57f209d72da0e1, 10s elapsed]
module.ec2.aws_security_group.instance-sg: Destruction complete after 11s

Destroy complete! Resources: 2 destroyed.
Releasing state lock. This may take a few moments...
```
